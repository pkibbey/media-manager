# Supabase
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=
NEXT_PUBLIC_MEDIA_SCAN_PATH=

# External GPU processing server (running TensorFlow)
TENSORFLOW_SERVER_URL=

# TensorFlow Configuration
# Enable Metal GPU acceleration on M-series Macs
TF_METAL_DEVICE=1

# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379

# CPU/GPU Intensive Workers: For workers running TensorFlow models or other ML tasks, keeping
# concurrency closer to your CPU core count prevents resource contention. These tasks benefit less
# from high concurrency because they're actively using computational resources, not waiting on IO.
OBJECT_DETECTION_WORKER_CONCURRENCY=3
CONTENT_WARNINGS_WORKER_CONCURRENCY=3
ADVANCED_ANALYSIS_WORKER_CONCURRENCY=4

# Mixed Workers: For tasks with both significant CPU and IO components, a moderate increase in
# concurrency (8-15) can help balance resource usage effectively.
DUPLICATES_WORKER_CONCURRENCY=10

# IO Intensive Workers: For workers that mostly read files, call APIs, or update databases,
# much higher concurrency settings (20-50) can significantly improve throughput as these
# operations spend most of their time waiting.
EXIF_WORKER_CONCURRENCY=30
THUMBNAIL_WORKER_CONCURRENCY=20